{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6a1bf1-b10d-40d1-9928-a687d040472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import onnx\n",
    "import sys\n",
    "import re\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49eca97c-cb70-45ec-90e1-145e00193f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "from classes.dataset_utils.toTorchDataset import ProcessedKit23TorchDataset\n",
    "from classes.models import resnet_model_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03377746-e08b-4e67-8635-7e0c2bc85f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.config_class import ProjectModelResnetConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e237497-f4ec-43dd-ada2-d8e7090b2e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = ProcessedKit23TorchDataset(train_data=True, test_size=0.25, dataset_dir =\"./dataset/affine_transformed\")\n",
    "test_data = ProcessedKit23TorchDataset(train_data=False, test_size=0.25, dataset_dir =\"./dataset/affine_transformed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1645aa2c-21e5-4db1-902c-88d7f61ceaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_path = \"../pretrainedModel/resnet_10_23dataset.pth\"\n",
    "checkpoint = []\n",
    "if torch.cuda.is_available():\n",
    "    checkpoint = torch.load(resume_path)\n",
    "else:\n",
    "    checkpoint = torch.load(resume_path, map_location=torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd5c09cd-f423-48c1-ab70-c8ffc95218d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_resnet_model, pro_resnet_params = resnet_model_generator.generate_model(ProjectModelResnetConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15707a1a-4fa9-4085-859c-3d73d1d1883e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint Key: module.conv1.weight                                          model key: conv1.weight                                                  torch.Size([64, 1, 7, 7, 7])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.bn1.weight                                            model key: bn1.weight                                                    torch.Size([64])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.bn1.bias                                              model key: bn1.bias                                                      torch.Size([64])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.bn1.running_mean                                      model key: bn1.running_mean                                              torch.Size([64])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.bn1.running_var                                       model key: bn1.running_var                                               torch.Size([64])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.bn1.num_batches_tracked                               model key: bn1.num_batches_tracked                                       torch.Size([])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer1.0.conv1.weight                                 model key: layer1.0.conv1.weight                                         torch.Size([64, 64, 3, 3, 3])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer1.0.bn1.weight                                   model key: layer1.0.bn1.weight                                           torch.Size([64])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer1.0.bn1.bias                                     model key: layer1.0.bn1.bias                                             torch.Size([64])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer1.0.bn1.running_mean                             model key: layer1.0.bn1.running_mean                                     torch.Size([64])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer1.0.bn1.running_var                              model key: layer1.0.bn1.running_var                                      torch.Size([64])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer1.0.bn1.num_batches_tracked                      model key: layer1.0.bn1.num_batches_tracked                              torch.Size([])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer1.0.conv2.weight                                 model key: layer1.0.conv2.weight                                         torch.Size([64, 64, 3, 3, 3])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer1.0.bn2.weight                                   model key: layer1.0.bn2.weight                                           torch.Size([64])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer1.0.bn2.bias                                     model key: layer1.0.bn2.bias                                             torch.Size([64])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer1.0.bn2.running_mean                             model key: layer1.0.bn2.running_mean                                     torch.Size([64])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer1.0.bn2.running_var                              model key: layer1.0.bn2.running_var                                      torch.Size([64])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer1.0.bn2.num_batches_tracked                      model key: layer1.0.bn2.num_batches_tracked                              torch.Size([])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer2.0.conv1.weight                                 model key: layer2.0.conv1.weight                                         torch.Size([128, 64, 3, 3, 3])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer2.0.bn1.weight                                   model key: layer2.0.bn1.weight                                           torch.Size([128])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer2.0.bn1.bias                                     model key: layer2.0.bn1.bias                                             torch.Size([128])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer2.0.bn1.running_mean                             model key: layer2.0.bn1.running_mean                                     torch.Size([128])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer2.0.bn1.running_var                              model key: layer2.0.bn1.running_var                                      torch.Size([128])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer2.0.bn1.num_batches_tracked                      model key: layer2.0.bn1.num_batches_tracked                              torch.Size([])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer2.0.conv2.weight                                 model key: layer2.0.conv2.weight                                         torch.Size([128, 128, 3, 3, 3])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer2.0.bn2.weight                                   model key: layer2.0.bn2.weight                                           torch.Size([128])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer2.0.bn2.bias                                     model key: layer2.0.bn2.bias                                             torch.Size([128])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer2.0.bn2.running_mean                             model key: layer2.0.bn2.running_mean                                     torch.Size([128])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer2.0.bn2.running_var                              model key: layer2.0.bn2.running_var                                      torch.Size([128])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer2.0.bn2.num_batches_tracked                      model key: layer2.0.bn2.num_batches_tracked                              torch.Size([])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer2.0.downsample.0.weight                          model key: layer2.0.downsample.0.weight                                  torch.Size([128, 64, 1, 1, 1])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer2.0.downsample.1.weight                          model key: layer2.0.downsample.1.weight                                  torch.Size([128])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer2.0.downsample.1.bias                            model key: layer2.0.downsample.1.bias                                    torch.Size([128])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer2.0.downsample.1.running_mean                    model key: layer2.0.downsample.1.running_mean                            torch.Size([128])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer2.0.downsample.1.running_var                     model key: layer2.0.downsample.1.running_var                             torch.Size([128])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer2.0.downsample.1.num_batches_tracked             model key: layer2.0.downsample.1.num_batches_tracked                     torch.Size([])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer3.0.conv1.weight                                 model key: layer3.0.conv1.weight                                         torch.Size([256, 128, 3, 3, 3])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer3.0.bn1.weight                                   model key: layer3.0.bn1.weight                                           torch.Size([256])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer3.0.bn1.bias                                     model key: layer3.0.bn1.bias                                             torch.Size([256])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer3.0.bn1.running_mean                             model key: layer3.0.bn1.running_mean                                     torch.Size([256])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer3.0.bn1.running_var                              model key: layer3.0.bn1.running_var                                      torch.Size([256])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer3.0.bn1.num_batches_tracked                      model key: layer3.0.bn1.num_batches_tracked                              torch.Size([])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer3.0.conv2.weight                                 model key: layer3.0.conv2.weight                                         torch.Size([256, 256, 3, 3, 3])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer3.0.bn2.weight                                   model key: layer3.0.bn2.weight                                           torch.Size([256])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer3.0.bn2.bias                                     model key: layer3.0.bn2.bias                                             torch.Size([256])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer3.0.bn2.running_mean                             model key: layer3.0.bn2.running_mean                                     torch.Size([256])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer3.0.bn2.running_var                              model key: layer3.0.bn2.running_var                                      torch.Size([256])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer3.0.bn2.num_batches_tracked                      model key: layer3.0.bn2.num_batches_tracked                              torch.Size([])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer3.0.downsample.0.weight                          model key: layer3.0.downsample.0.weight                                  torch.Size([256, 128, 1, 1, 1])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer3.0.downsample.1.weight                          model key: layer3.0.downsample.1.weight                                  torch.Size([256])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer3.0.downsample.1.bias                            model key: layer3.0.downsample.1.bias                                    torch.Size([256])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer3.0.downsample.1.running_mean                    model key: layer3.0.downsample.1.running_mean                            torch.Size([256])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer3.0.downsample.1.running_var                     model key: layer3.0.downsample.1.running_var                             torch.Size([256])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer3.0.downsample.1.num_batches_tracked             model key: layer3.0.downsample.1.num_batches_tracked                     torch.Size([])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer4.0.conv1.weight                                 model key: layer4.0.conv1.weight                                         torch.Size([512, 256, 3, 3, 3])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer4.0.bn1.weight                                   model key: layer4.0.bn1.weight                                           torch.Size([512])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer4.0.bn1.bias                                     model key: layer4.0.bn1.bias                                             torch.Size([512])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer4.0.bn1.running_mean                             model key: layer4.0.bn1.running_mean                                     torch.Size([512])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer4.0.bn1.running_var                              model key: layer4.0.bn1.running_var                                      torch.Size([512])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer4.0.bn1.num_batches_tracked                      model key: layer4.0.bn1.num_batches_tracked                              torch.Size([])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer4.0.conv2.weight                                 model key: layer4.0.conv2.weight                                         torch.Size([512, 512, 3, 3, 3])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer4.0.bn2.weight                                   model key: layer4.0.bn2.weight                                           torch.Size([512])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer4.0.bn2.bias                                     model key: layer4.0.bn2.bias                                             torch.Size([512])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer4.0.bn2.running_mean                             model key: layer4.0.bn2.running_mean                                     torch.Size([512])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer4.0.bn2.running_var                              model key: layer4.0.bn2.running_var                                      torch.Size([512])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer4.0.bn2.num_batches_tracked                      model key: layer4.0.bn2.num_batches_tracked                              torch.Size([])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer4.0.downsample.0.weight                          model key: layer4.0.downsample.0.weight                                  torch.Size([512, 256, 1, 1, 1])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer4.0.downsample.1.weight                          model key: layer4.0.downsample.1.weight                                  torch.Size([512])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer4.0.downsample.1.bias                            model key: layer4.0.downsample.1.bias                                    torch.Size([512])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer4.0.downsample.1.running_mean                    model key: layer4.0.downsample.1.running_mean                            torch.Size([512])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer4.0.downsample.1.running_var                     model key: layer4.0.downsample.1.running_var                             torch.Size([512])  <class 'torch.Tensor'>\n",
      "Checkpoint Key: module.layer4.0.downsample.1.num_batches_tracked             model key: layer4.0.downsample.1.num_batches_tracked                     torch.Size([])  <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "net_dict = proj_resnet_model.state_dict()\n",
    "pretrain_dict = {}\n",
    "for k,v in checkpoint['state_dict'].items():\n",
    "    has_match = False\n",
    "    for model_key in net_dict.keys():\n",
    "        k_len = len(model_key)\n",
    "        c_key = k[7:]\n",
    "        if c_key == model_key:\n",
    "            pretrain_dict[model_key] = v\n",
    "            print(\"Checkpoint Key: {:60s} model key: {:60s}  {}  {}\".format(k, model_key, v.size(), type(v)))\n",
    "            has_match = True\n",
    "            break\n",
    "    if not has_match:\n",
    "        print(\"Checkpoint Key: {:60s} has no match\".format(k))\n",
    "    \n",
    "net_dict.update(pretrain_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaa9ad7c-3a1d-438a-a734-9efdbcc9ecfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_resnet_model.load_state_dict(net_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ebc8868-c31b-4fca-9eaa-74e4be20da4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(training_data, batch_size=ProjectModelResnetConfig.batch_size, shuffle=True, num_workers=ProjectModelResnetConfig.num_workers, pin_memory=ProjectModelResnetConfig.pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f39c8cda-a5f2-4329-bcd4-f9d7bb93bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "optimizer = optim.SGD(proj_resnet_model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-3)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "if not ProjectModelResnetConfig.no_cuda:\n",
    "    ProjectModelResnetConfig.pin_memory = True\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a55372d7-33d2-44c2-9d27-3698440d027c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch=    0 Learning Rate=[0.001]\n",
      "Epoch:0 Batch:0 loss = 1.275, avg_batch_time = 7.245\n",
      "Epoch:0 Batch:50 loss = 0.114, avg_batch_time = 7.853\n",
      "Epoch:0 Batch:100 loss = 0.057, avg_batch_time = 8.485\n",
      "Epoch:0 Batch:150 loss = 0.031, avg_batch_time = 8.825\n",
      "Epoch:0 Batch:200 loss = 0.030, avg_batch_time = 9.017\n",
      "Epoch:0 Batch:250 loss = 0.022, avg_batch_time = 9.066\n",
      "Epoch:0 Batch:300 loss = 0.020, avg_batch_time = 9.035\n",
      "Epoch:0 Batch:350 loss = 0.015, avg_batch_time = 8.980\n",
      "current epoch=    1 Learning Rate=[0.00099]\n",
      "Epoch:1 Batch:0 loss = 0.013, avg_batch_time = 8.966\n",
      "Epoch:1 Batch:50 loss = 0.015, avg_batch_time = 8.826\n",
      "Epoch:1 Batch:100 loss = 0.014, avg_batch_time = 8.771\n",
      "Epoch:1 Batch:150 loss = 0.010, avg_batch_time = 8.696\n",
      "Epoch:1 Batch:200 loss = 0.008, avg_batch_time = 8.627\n",
      "Epoch:1 Batch:250 loss = 0.009, avg_batch_time = 8.570\n",
      "Epoch:1 Batch:300 loss = 0.007, avg_batch_time = 8.523\n",
      "Epoch:1 Batch:350 loss = 0.006, avg_batch_time = 8.479\n",
      "current epoch=    2 Learning Rate=[0.0009801]\n",
      "Epoch:2 Batch:0 loss = 0.008, avg_batch_time = 8.481\n",
      "Epoch:2 Batch:50 loss = 0.007, avg_batch_time = 8.432\n",
      "Epoch:2 Batch:100 loss = 0.006, avg_batch_time = 8.402\n",
      "Epoch:2 Batch:150 loss = 0.008, avg_batch_time = 8.370\n",
      "Epoch:2 Batch:200 loss = 0.007, avg_batch_time = 8.340\n",
      "Epoch:2 Batch:250 loss = 0.005, avg_batch_time = 8.311\n",
      "Epoch:2 Batch:300 loss = 0.005, avg_batch_time = 8.284\n",
      "Epoch:2 Batch:350 loss = 0.005, avg_batch_time = 8.258\n",
      "current epoch=    3 Learning Rate=[0.000970299]\n",
      "Epoch:3 Batch:0 loss = 0.006, avg_batch_time = 8.260\n",
      "Epoch:3 Batch:50 loss = 0.005, avg_batch_time = 8.230\n",
      "Epoch:3 Batch:100 loss = 0.004, avg_batch_time = 8.209\n",
      "Epoch:3 Batch:150 loss = 0.005, avg_batch_time = 8.191\n",
      "Epoch:3 Batch:200 loss = 0.005, avg_batch_time = 8.169\n",
      "Epoch:3 Batch:250 loss = 0.004, avg_batch_time = 8.151\n",
      "Epoch:3 Batch:300 loss = 0.003, avg_batch_time = 8.131\n",
      "Epoch:3 Batch:350 loss = 0.005, avg_batch_time = 8.114\n",
      "current epoch=    4 Learning Rate=[0.0009605960099999999]\n",
      "Epoch:4 Batch:0 loss = 0.004, avg_batch_time = 8.115\n",
      "Epoch:4 Batch:50 loss = 0.004, avg_batch_time = 8.093\n",
      "Epoch:4 Batch:100 loss = 0.005, avg_batch_time = 8.076\n",
      "Epoch:4 Batch:150 loss = 0.003, avg_batch_time = 8.060\n",
      "Epoch:4 Batch:200 loss = 0.004, avg_batch_time = 8.045\n",
      "Epoch:4 Batch:250 loss = 0.003, avg_batch_time = 8.030\n",
      "Epoch:4 Batch:300 loss = 0.003, avg_batch_time = 8.020\n",
      "Epoch:4 Batch:350 loss = 0.007, avg_batch_time = 8.008\n",
      "current epoch=    5 Learning Rate=[0.0009509900498999999]\n",
      "Epoch:5 Batch:0 loss = 0.003, avg_batch_time = 8.010\n",
      "Epoch:5 Batch:50 loss = 0.003, avg_batch_time = 7.995\n",
      "Epoch:5 Batch:100 loss = 0.003, avg_batch_time = 7.986\n",
      "Epoch:5 Batch:150 loss = 0.004, avg_batch_time = 7.976\n",
      "Epoch:5 Batch:200 loss = 0.002, avg_batch_time = 7.968\n",
      "Epoch:5 Batch:250 loss = 0.002, avg_batch_time = 7.960\n",
      "Epoch:5 Batch:300 loss = 0.003, avg_batch_time = 7.953\n",
      "Epoch:5 Batch:350 loss = 0.003, avg_batch_time = 7.945\n",
      "current epoch=    6 Learning Rate=[0.0009414801494009999]\n",
      "Epoch:6 Batch:0 loss = 0.003, avg_batch_time = 7.948\n",
      "Epoch:6 Batch:50 loss = 0.002, avg_batch_time = 7.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x109eb6290>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/opt/pyenv/versions/3.10.9/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
      "    def __del__(self):\n",
      "  File \"/usr/local/opt/pyenv/versions/3.10.9/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 69809) is killed by signal: Interrupt: 2. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_preds, resized_segs)\n\u001b[1;32m     32\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 33\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m                \n\u001b[1;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     37\u001b[0m total_processed_batches \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m*\u001b[39m batches_per_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m batch_idx\n",
      "File \u001b[0;32m/usr/local/opt/pyenv/versions/3.10.9/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/opt/pyenv/versions/3.10.9/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_time_start = time.time()\n",
    "batches_per_epoch = len(data_loader)\n",
    "epoch_list = []\n",
    "loss_list = []\n",
    "lr_list = []\n",
    "for epoch in range(ProjectModelResnetConfig.max_epoch):\n",
    "    current_lr = scheduler.get_last_lr()\n",
    "    print(\"current epoch={:5d} Learning Rate={}\".format(epoch, current_lr))\n",
    "    lr_list.append(current_lr)\n",
    "    \n",
    "    for batch_idx, batch_data  in enumerate(data_loader):\n",
    "        imgs, segs = batch_data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        y_preds = proj_resnet_model(imgs.float())\n",
    "\n",
    "        [n, _, z_size, y_size, x_size] = y_preds.shape\n",
    "\n",
    "        resized_segs = np.zeros([n, z_size, y_size, x_size])\n",
    "        for idx in range(n):\n",
    "            seg = segs[idx][0]\n",
    "            [ori_z, ori_y, ori_x] = seg.shape \n",
    "            scale = [z_size/ori_z, y_size/ori_y, x_size/ori_x]\n",
    "            this_affine = np.array([[scale[0], 0, 0],[0, scale[1], 0],[0, 0, scale[2]]])\n",
    "            resized_segs[idx] = ndimage.affine_transform(seg, this_affine, output_shape=resized_segs[idx].shape, cval=0)\n",
    "\n",
    "        resized_segs = torch.tensor(resized_segs).to(torch.int64)\n",
    "        loss = criterion(y_preds, resized_segs)\n",
    "        running_loss = loss.item()\n",
    "        loss.backward()                \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        total_processed_batches = epoch * batches_per_epoch + 1 + batch_idx\n",
    "        avg_batch_time = (time.time() - train_time_start) / total_processed_batches\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(\"Epoch:{} Batch:{} loss = {:.3f}, avg_batch_time = {:.3f}\".format(epoch, batch_idx, running_loss, avg_batch_time))\n",
    "    scheduler.step()\n",
    "    epoch_list.append(epoch)\n",
    "    loss_list.append(loss.item())\n",
    "    model_checkpoint_path = ProjectModelResnetConfig.save_checkpoint_pathname(epoch)\n",
    "    torch.save({'epoch_list': epoch_list, 'loss_list': loss_list, 'lr_list': lr_list, 'state_dict': proj_resnet_model.state_dict(),'optimizer': optimizer.state_dict()},model_checkpoint_path)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af147764-3aef-45fb-ab46-b99bcd743a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa7965-8f2b-4fde-a2a7-93b62bd780a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0d5aaa-54f4-4adf-960c-fd382ba5ed56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
